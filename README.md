# Multilabel-classification

Task 1:
- Trained word embeddings (CBOW, SkipGram, or FastText) using the `df_raw_small_hw.joblib` dataset with Gensim library. Saved the trained embeddings for future use.
- Demonstrated proficiency in data preprocessing, embedding training, and efficient storage and retrieval of word embeddings. Utilized Gensim library for streamlined implementation.

Task 2:
- Incorporated pre-trained embeddings (either online or previously trained) into a sklearn classification pipeline for multi-label classification. Evaluated the model using appropriate metrics and achieved reliable classification results.
- Showcased expertise in leveraging pre-trained embeddings, integrating them into a classification pipeline, and effectively utilizing sklearn library for streamlined model development.

Task 3:
- Part a: Conducted experiments with a small subset of data to explore various network architectures using pre-trained embeddings. Logged and documented the experiments on wandb, ensuring transparency and reproducibility.
- Part b: Performed regularization experiments with the complete dataset, incorporating pre-trained embeddings and utilizing learning rate schedulers for enhanced model performance. Logged the experiments on wandb, showcasing a comprehensive understanding of regularization techniques and their impact on neural network training.
